{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac71ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b91a2ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Processing downloads/01.png\n",
      "-- File Name: downloads/01.png, Average Value: 0.27622565936709126\n",
      "--   Excluded Pixels: 32208, Included Pixels: 382488\n",
      "-- Processing downloads/02.png\n",
      "-- File Name: downloads/02.png, Average Value: 0.17743368613615576\n",
      "--   Excluded Pixels: 32046, Included Pixels: 382650\n",
      "-- Processing downloads/03.png\n",
      "-- File Name: downloads/03.png, Average Value: 0.22353439478779633\n",
      "--   Excluded Pixels: 32516, Included Pixels: 382180\n",
      "-- Processing downloads/04.png\n",
      "-- File Name: downloads/04.png, Average Value: 0.2850669278485145\n",
      "--   Excluded Pixels: 31821, Included Pixels: 382875\n",
      "Day 0 average: 0.24056516703488948\n",
      "-- Processing downloads/05.png\n",
      "-- File Name: downloads/05.png, Average Value: 0.3833534798198996\n",
      "--   Excluded Pixels: 32909, Included Pixels: 381787\n",
      "-- Processing downloads/06.png\n",
      "-- File Name: downloads/06.png, Average Value: 0.32784692505675933\n",
      "--   Excluded Pixels: 32380, Included Pixels: 382316\n",
      "-- Processing downloads/07.png\n",
      "-- File Name: downloads/07.png, Average Value: 0.4803795143554805\n",
      "--   Excluded Pixels: 32194, Included Pixels: 382502\n",
      "-- Processing downloads/08.png\n",
      "-- File Name: downloads/08.png, Average Value: 0.5085288676411327\n",
      "--   Excluded Pixels: 32538, Included Pixels: 382158\n",
      "Day 1 average: 0.425027196718318\n",
      "-- Processing downloads/09.png\n",
      "-- File Name: downloads/09.png, Average Value: 0.5044733994306879\n",
      "--   Excluded Pixels: 32129, Included Pixels: 382567\n",
      "-- Processing downloads/10.png\n",
      "-- File Name: downloads/10.png, Average Value: 0.3872352621300336\n",
      "--   Excluded Pixels: 32195, Included Pixels: 382501\n",
      "-- Processing downloads/11.png\n",
      "-- File Name: downloads/11.png, Average Value: 0.2597459944473083\n",
      "--   Excluded Pixels: 32539, Included Pixels: 382157\n",
      "-- Processing downloads/12.png\n",
      "-- File Name: downloads/12.png, Average Value: 0.2602543148535565\n",
      "--   Excluded Pixels: 32296, Included Pixels: 382400\n",
      "Day 2 average: 0.3529272427153966\n",
      "-- Processing downloads/13.png\n",
      "-- File Name: downloads/13.png, Average Value: 0.21339459312351658\n",
      "--   Excluded Pixels: 32553, Included Pixels: 382143\n",
      "-- Processing downloads/14.png\n",
      "-- File Name: downloads/14.png, Average Value: 0.04039233858510967\n",
      "--   Excluded Pixels: 32730, Included Pixels: 381966\n",
      "-- Processing downloads/15.png\n",
      "-- File Name: downloads/15.png, Average Value: -0.05788150629626823\n",
      "--   Excluded Pixels: 32009, Included Pixels: 382687\n",
      "-- Processing downloads/16.png\n",
      "-- File Name: downloads/16.png, Average Value: 0.11162318996143646\n",
      "--   Excluded Pixels: 32729, Included Pixels: 381967\n",
      "Day 3 average: 0.07688215384344863\n",
      "-- Processing downloads/17.png\n",
      "-- File Name: downloads/17.png, Average Value: 0.07804907899972773\n",
      "--   Excluded Pixels: 32720, Included Pixels: 381976\n",
      "-- Processing downloads/18.png\n",
      "-- File Name: downloads/18.png, Average Value: -0.04206947949217473\n",
      "--   Excluded Pixels: 32281, Included Pixels: 382415\n",
      "-- Processing downloads/19.png\n",
      "-- File Name: downloads/19.png, Average Value: -0.02185622668673516\n",
      "--   Excluded Pixels: 32671, Included Pixels: 382025\n",
      "-- Processing downloads/20.png\n",
      "-- File Name: downloads/20.png, Average Value: 0.09539205036253698\n",
      "--   Excluded Pixels: 32666, Included Pixels: 382030\n",
      "Day 4 average: 0.0273788557958387\n",
      "-- Processing downloads/21.png\n",
      "-- File Name: downloads/21.png, Average Value: 0.10147282429482918\n",
      "--   Excluded Pixels: 32590, Included Pixels: 382106\n",
      "-- Processing downloads/22.png\n",
      "-- File Name: downloads/22.png, Average Value: -0.0020794286864441115\n",
      "--   Excluded Pixels: 32139, Included Pixels: 382557\n",
      "-- Processing downloads/23.png\n",
      "-- File Name: downloads/23.png, Average Value: -0.02813833570412518\n",
      "--   Excluded Pixels: 32264, Included Pixels: 382432\n",
      "-- Processing downloads/24.png\n",
      "-- File Name: downloads/24.png, Average Value: 0.16072147589589664\n",
      "--   Excluded Pixels: 32230, Included Pixels: 382466\n",
      "Day 5 average: 0.057994133950039134\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import colorsys\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    # Convert a 6-char hexadecimal color to RGB tuple\n",
    "    r = int(hex_color[0:2], 16)\n",
    "    g = int(hex_color[2:4], 16)\n",
    "    b = int(hex_color[4:6], 16)\n",
    "    return r, g, b\n",
    "\n",
    "def calculate_average_anomaly(image_path, top_left, bottom_right, map_for_rgb_to_anomaly):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "\n",
    "    # Extract the rectangle box region\n",
    "    box_left = max(0, top_left[0])\n",
    "    box_upper = max(0, top_left[1])\n",
    "    box_right = min(width, bottom_right[0])\n",
    "    box_lower = min(height, bottom_right[1])\n",
    "\n",
    "    # Initialize the list to store the chart_anomaly_pixel_values\n",
    "    chart_anomaly_pixel_values = []\n",
    "\n",
    "    # Initialize counters for excluded and included pixels\n",
    "    excluded_pixels = 0\n",
    "    included_pixels = 0\n",
    "\n",
    "    # Create map_for_rgb_hues_to_anomaly by converting hex RGB values to Hue values\n",
    "    map_for_rgb_hues_to_anomaly = [colorsys.rgb_to_hsv(*hex_to_rgb(hex_color))[0] for hex_color in map_for_rgb_to_anomaly.keys()]\n",
    "\n",
    "    # Iterate through the box and apply the mapping\n",
    "    for y in range(box_upper, box_lower):\n",
    "        for x in range(box_left, box_right):\n",
    "            pixel_value = img.getpixel((x, y))\n",
    "            \n",
    "            # Check if the pixel meets the exclusion criteria (for both indexed PNG and RGB images)\n",
    "            if isinstance(pixel_value, int):  # Indexed PNG image\n",
    "                r, g, b = img.getpalette()[pixel_value * 3:pixel_value * 3 + 3]\n",
    "            else:  # RGB image\n",
    "                r, g, b = pixel_value\n",
    "\n",
    "            # Check if the pixel meets the exclusion criteria\n",
    "            h, s, v = colorsys.rgb_to_hsv(r / 255.0, g / 255.0, b / 255.0)\n",
    "            if v * 100 < 38 or colorsys.rgb_to_hsv(r, g, b)[2] * 100 < 28:\n",
    "                excluded_pixels += 1\n",
    "                continue\n",
    "\n",
    "            included_pixels += 1\n",
    "\n",
    "            # Calculate the differences between the pixel Hue and map_for_rgb_hues_to_anomaly\n",
    "            pixel_hue = colorsys.rgb_to_hsv(r / 255.0, g / 255.0, b / 255.0)[0]\n",
    "            hue_differences = [abs(pixel_hue - hue) for hue in map_for_rgb_hues_to_anomaly]\n",
    "\n",
    "            # Find the index of the mapping with the smallest difference\n",
    "            min_diff_index = hue_differences.index(min(hue_differences))\n",
    "\n",
    "            # Get the corresponding anomaly value from the map\n",
    "            hex_color = list(map_for_rgb_to_anomaly.keys())[min_diff_index]\n",
    "            chart_anomaly_pixel_values.append(map_for_rgb_to_anomaly[hex_color])\n",
    "\n",
    "    # Calculate and print the average value\n",
    "    if chart_anomaly_pixel_values:\n",
    "        average_value = sum(chart_anomaly_pixel_values) / len(chart_anomaly_pixel_values)\n",
    "        print(f\"-- File Name: {image_path}, Average Value: {average_value}\")\n",
    "\n",
    "    # Print the number of excluded and included pixels\n",
    "    print(f\"--   Excluded Pixels: {excluded_pixels}, Included Pixels: {included_pixels}\")\n",
    "    return average_value\n",
    "\n",
    "# Define the parameters for calculate_average_anomaly()\n",
    "map_for_rgb_to_anomaly = {\n",
    "    \"ffcdba\": -30,\n",
    "    \"f8bac5\": -26,\n",
    "    \"f3a8d2\": -22,\n",
    "    \"eb95dd\": -19,\n",
    "    \"e684e8\": -17,\n",
    "    \"df71f4\": -15,\n",
    "    \"b65bec\": -13,\n",
    "    \"9157db\": -11,\n",
    "    \"6c52ca\": -9,\n",
    "    \"484fb8\": -7.5,\n",
    "    \"244ba6\": -6.5,\n",
    "    \"004693\": -5.5,\n",
    "    \"135ead\": -4.5,\n",
    "    \"2874c6\": -3.875,\n",
    "    \"3b8adf\": -2.875,\n",
    "    \"64b7f8\": -2.25,\n",
    "    \"78cdf7\": -1.75,\n",
    "    \"8ce3f6\": -1.25,\n",
    "    \"9ff8f4\": -0.75,\n",
    "    \"ffffff\": 0.0,\n",
    "    \"fffebe\": 0.75,\n",
    "    \"feeaa0\": 1.25,\n",
    "    \"fdd283\": 1.75,\n",
    "    \"fdb365\": 2.25,\n",
    "    \"f88b51\": 2.875,\n",
    "    \"ef633e\": 3.875,\n",
    "    \"dd3d2d\": 4.5,\n",
    "    \"c21c26\": 5.5,\n",
    "    \"9d2539\": 6.5,\n",
    "    \"ba4355\": 7.5,\n",
    "    \"d96073\": 9,\n",
    "    \"f186a8\": 11,\n",
    "    \"fda7dd\": 13,\n",
    "    \"e497c0\": 15,\n",
    "    \"cb86a4\": 17,\n",
    "    \"b17386\": 19,\n",
    "    \"9b646e\": 22,\n",
    "    \"7f544f\": 26,\n",
    "    \"66462f\": 30\n",
    "}\n",
    "\n",
    "top_left = (35, 47)\n",
    "bottom_right = (969, 491)\n",
    "\n",
    "# Loop through all files in the \"downloads/\" folder\n",
    "downloads_folder = \"downloads/\"\n",
    "\n",
    "image_count = 0\n",
    "day_average_values = []\n",
    "for filename in sorted(os.listdir(downloads_folder)):\n",
    "    \n",
    "    if filename.lower().endswith(\".png\"):\n",
    "        image_path = os.path.join(downloads_folder, filename)\n",
    "        print(f\"-- Processing {image_path}\")\n",
    "        period_average_value = calculate_average_anomaly(image_path, top_left, bottom_right, map_for_rgb_to_anomaly)\n",
    "        # four periods in the day 00,06,12,18\n",
    "        # use 0 index for image_count to figure out what period we are in\n",
    "        day = math.floor(image_count / 4)\n",
    "        if image_count % 4 == 0:\n",
    "            day_average_values = []\n",
    "        day_average_values.append(period_average_value)\n",
    "        if image_count % 4 == 3:\n",
    "            day_average = np.average(day_average_values)\n",
    "            print(f\"Day {day} average: {day_average}\")\n",
    "        image_count += 1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e4b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2095e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_file(url, folder_path):\n",
    "    response = requests.get(url)\n",
    "    file_name = os.path.basename(url)\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "def get_file_urls(base_url):\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        href = link.get('href')\n",
    "        if href and not href.startswith('../') and href.startswith('geavg.t00z.pgrb2a.0p50_bcf') and 'idx' not in href:\n",
    "            urls.append(href)\n",
    "    return urls\n",
    "\n",
    "# MAKE SURE THERE IS NO TRAILING SLASH\n",
    "base_urls = [\n",
    "    \"https://nomads.ncep.noaa.gov/pub/data/nccf/com/naefs/prod/gefs.20230726/00/pgrb2ap5_bc\",\n",
    "    \"https://nomads.ncep.noaa.gov/pub/data/nccf/com/naefs/prod/gefs.20230727/00/pgrb2ap5_bc\"\n",
    "]\n",
    "\n",
    "num_urls = len(base_urls)\n",
    "cur_url_count = 0\n",
    "for base_url in base_urls:\n",
    "    folder_path = os.path.basename(os.path.normpath(\n",
    "        base_url.split('/')[-3]\n",
    "    ))\n",
    "    print(folder_path)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    cur_url_count += 1\n",
    "    print(f\"Processing {cur_url_count} / {num_urls} folders to download GEFS, bias corrected, 2m ensemble mean temperatures\")\n",
    "\n",
    "    file_urls = get_file_urls(base_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    i = 0\n",
    "    numfiles = len(file_urls)\n",
    "    for file_url in file_urls:\n",
    "        download_url = f\"https://nomads.ncep.noaa.gov/cgi-bin/filter_gensbc.pl?dir=/{base_url.split('https://nomads.ncep.noaa.gov/pub/data/nccf/com/naefs/prod/')[-1]}&file={file_url}&var_TMP=on&lev_2_m_above_ground=on\"\n",
    "        i += 1\n",
    "        print(f\" - Downloading {i} / {numfiles} : {download_url}\")\n",
    "        download_file(download_url, folder_path)\n",
    "        time.sleep(2)  # Pause for 2 seconds between downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d1a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636b84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
