{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "89a96aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "def get_date(day_of_year, year):\n",
    "    # Create a datetime object for January 1st of the given year\n",
    "    base_date = datetime.datetime(year, 1, 1)\n",
    "    \n",
    "    # Add the number of days to the base date to get the target date\n",
    "    target_date = base_date + datetime.timedelta(days=day_of_year - 1)\n",
    "    \n",
    "    # Format the date as \"{Month} {Day}, {Year}\"\n",
    "    formatted_date = target_date.strftime(\"%B %d, %Y\")\n",
    "    \n",
    "    return formatted_date\n",
    "\n",
    "def calculate_bias(data, historical_temps, weight_prev_year):\n",
    "    # Calculate the bias from current data and historical data\n",
    "    # Uses a weighted rolling bias that decreases linearly beyond extrapolation date\n",
    "    # Rolling bias is weighted relative to the yearly average bias\n",
    "    filtered_data = list(filter(lambda item: item is not None, data))\n",
    "    # this includes la nina years so it isn't very good (need to fix)\n",
    "    bias = [None] * 366\n",
    "    bias_rolling = 0\n",
    "    bias_total = 0\n",
    "    bias_count = 0\n",
    "    bias_avg = 0\n",
    "    # only bias against recent era\n",
    "    for i in range(0, len(historical_temps)):\n",
    "        filtered_historical = list(filter(lambda item: item is not None, historical_temps[i]))\n",
    "        historical_avg = sum(filtered_historical) / len(filtered_historical)\n",
    "        if data[i]:\n",
    "            bias_rolling = data[i] - historical_avg\n",
    "            bias[i] = bias_rolling\n",
    "            bias_total += bias_rolling\n",
    "            bias_count += 1\n",
    "        else:\n",
    "            bias_prev_year = filtered_historical[len(filtered_historical) - 1] - historical_avg\n",
    "            bias_avg = bias_total / bias_count\n",
    "            extended = i - bias_count + 1\n",
    "            days_left = 366 - extended\n",
    "            # dumb interpolation for bias\n",
    "            # decrease the weight of the rolling bias linearly in time against the bias_avg for this year so far\n",
    "            weight = (days_left - extended) / days_left\n",
    "            bias[i] = (weight * bias_rolling) + ((1 - weight) * (1 - weight_prev_year) * bias_avg) + ((1 - weight) * weight_prev_year * bias_prev_year)\n",
    "    return bias\n",
    "\n",
    "def run_extrapolation(extrapolate_year, weight_prev_year, last_day, n, filepath, graph):\n",
    "    # Step 1: Load and parse the JSON file\n",
    "    with open(filepath) as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Step 2: Filter the data to include only four-digit years\n",
    "    filtered_data = [entry for entry in data if len(entry['name']) == 4]\n",
    "\n",
    "    # Step 3: Separate historical data and partially filled in data from extrapolate_year\n",
    "    historical_data = [entry for entry in filtered_data if int(entry['name']) < extrapolate_year]\n",
    "    partial_data = [entry for entry in filtered_data if int(entry['name']) == extrapolate_year]\n",
    "\n",
    "    # Step 4: Extract historical temperatures for each day\n",
    "    historical_temps = [[] for _ in range(366)]  # Assuming 365 days in a year, no leap years\n",
    "    for entry in historical_data:\n",
    "        for i, temp in enumerate(entry['data']):\n",
    "            historical_temps[i].append(temp)\n",
    "\n",
    "    # Step 5: Monte Carlo simulations to fill in missing data for projected year\n",
    "    bias = [None] * 366\n",
    "    simulated_data_adj = []\n",
    "    max_obs_temp = 0\n",
    "    start_index = 0\n",
    "    for entry in partial_data:\n",
    "        filtered_data = list(filter(lambda item: item is not None, entry['data']))\n",
    "        max_obs_temp = max(filtered_data)\n",
    "        num_missing_values = entry['data'].count(None)\n",
    "        simulated_temps_adj = [None] * 366\n",
    "        start_index = entry['data'].index(None)  # Index where missing data starts\n",
    "\n",
    "        bias = calculate_bias(entry['data'], historical_temps, weight_prev_year)\n",
    "        for i in range(start_index, start_index + num_missing_values):\n",
    "            count = 0\n",
    "            simulated_total = 0\n",
    "            while count < n:\n",
    "                c = random.choice(historical_temps[i])\n",
    "                if c:\n",
    "                    if bias[i]:\n",
    "                        simulated_total += c + bias[i]\n",
    "                    else:\n",
    "                        simulated_total += c\n",
    "                    count += 1\n",
    "            simulated_temps_adj[i] = simulated_total / n\n",
    "        simulated_data_adj.append({'name': entry['name'], 'data': simulated_temps_adj})\n",
    "\n",
    "    if graph:\n",
    "        # code for looking at graphs and printing out all temps\n",
    "        print(f\"Observed maximum: {max_obs_temp}\")\n",
    "        print(f\"Possible days of observed maximum being exceeded:\")\n",
    "        print(f\"Projected days where observed maximum is surpassed:\")\n",
    "        for i in range(start_index, 366):\n",
    "            temp = simulated_data_adj[0]['data'][i]\n",
    "            if temp > max_obs_temp:\n",
    "                formatted_date = get_date(i + 1, extrapolate_year)\n",
    "                count += 1\n",
    "                temp_str = str(round(temp, 3))\n",
    "                print(f\"{formatted_date}: {temp_str}\")\n",
    "        return count\n",
    "    else:\n",
    "        #count maximum breaking days up to last_day\n",
    "        count = 0\n",
    "        for i in range(start_index, last_day):\n",
    "            temp = simulated_data_adj[0]['data'][i]\n",
    "            if temp > max_obs_temp:\n",
    "                #formatted_date = get_date(i + 1, extrapolate_year)\n",
    "                count += 1\n",
    "                #temp_str = str(round(temp, 3))\n",
    "                #print(f\"{formatted_date}: {temp_str}\")\n",
    "        return count\n",
    "\n",
    "    # Step 6: Create a graph with simulated temperature data for projected year\n",
    "    x = range(1, len(partial_data[0]['data']) + 1)  # Assuming daily data\n",
    "    y = partial_data[0]['data']  # Assuming all days have the same temperature values\n",
    "    fig, ax = plt.subplots()\n",
    "    lbl = 'Observed ' + str(extrapolate_year) + ' Data'\n",
    "    ax.plot(x, y, label=lbl)\n",
    "    # use commented plots to examine the biases\n",
    "    ax.plot(x, simulated_data_adj[0]['data'], label='Simulated Data with Adjusted Bias')\n",
    "\n",
    "    ax.set_xlabel('Day')\n",
    "    ax.set_ylabel('Temperature')\n",
    "    lbl = 'Simulated Temperature Data for ' + str(extrapolate_year)\n",
    "    ax.set_title(lbl)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "020f6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CONFIG FOR MAIN PARAMETERS\n",
    "# number of simulations to average\n",
    "n = 1000\n",
    "# current year want to extrapolate data for that already have partial data\n",
    "extrapolate_year = 2023\n",
    "# also weight for previous year against bias avg for this year\n",
    "# in other words, how large will the bias at the end of this year be from the avg bias calculated of this year so far from the historical average\n",
    "# use a range of them to get a better idea\n",
    "weights_prev_year = [0.001, 0.01, 0.1, 0.2, 0.4, 0.8, 0.16, 0.32, 0.64, 0.99]\n",
    "# file path to local copy of json wih temp data\n",
    "# from https://climatereanalyzer.org/clim/t2_daily/json/cfsr_world_t2_day.json\n",
    "filepath = 'cfsr_world_t2_day.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG FOR SPECIFIC RUN\n",
    "# last day of year of range to check record for (July 12)\n",
    "last_day = 193\n",
    "\n",
    "graph = False\n",
    "formatted_date = get_date(last_day, extrapolate_year)\n",
    "print(f\"Chance of last record being broken before {formatted_date} :\")\n",
    "repeats = int(n / 10)\n",
    "print(\"========================================================\")\n",
    "print(\"Prev year weight: Probability of record being broken\")\n",
    "for weight_prev_year in weights_prev_year:\n",
    "    total = 0\n",
    "    for i in range(0, repeats):\n",
    "        total += run_extrapolation(extrapolate_year, weight_prev_year, last_day, n, filepath, graph)\n",
    "    avg = total / repeats\n",
    "    print(f\"{weight_prev_year}: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG FOR SPECIFIC RUN\n",
    "# last day of year of range to check record for (July 31)\n",
    "last_day = 212\n",
    "\n",
    "graph = True\n",
    "formatted_date = get_date(last_day, extrapolate_year)\n",
    "print(f\"Chance of last record being broken before {formatted_date} :\")\n",
    "repeats = int(n / 10)\n",
    "print(\"========================================================\")\n",
    "print(\"Prev year weight: Probability of record being broken\")\n",
    "for weight_prev_year in [0.001, 0.005, 0.01, 0.02, 0.04, 0.8, 0.16, 0.32, 0.64, 0.99]:\n",
    "    total = 0\n",
    "    for i in range(0, repeats):\n",
    "        total += run_extrapolation(extrapolate_year, weight_prev_year, last_day, n, filepath)\n",
    "    avg = total / repeats\n",
    "    print(f\"{weight_prev_year}: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph and show extrapolations for a single run\n",
    "# this is arbitrarily chosen\n",
    "weight_prev_year = 0.2\n",
    "graph = True\n",
    "run_extrapolation(extrapolate_year, weight_prev_year, last_day, n, filepath, graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
